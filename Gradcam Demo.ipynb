{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "250c347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.models import resnet50\n",
    "import torch\n",
    "\n",
    "model = resnet50(pretrained=True)\n",
    "target_layers = [model.layer4[-1]]\n",
    "\n",
    "image = torch.zeros(24,24, 3)\n",
    "input_tensor = torch.zeros(1,3,24,24)# Create an input tensor image for your model..\n",
    "# Note: input_tensor can be a batch tensor with several images!\n",
    "\n",
    "# Construct the CAM object once, and then re-use it on many images:\n",
    "cam = GradCAM(model=model, target_layer=target_layers[0], use_cuda=True)\n",
    "\n",
    "# You can also use it within a with statement, to make sure it is freed,\n",
    "# In case you need to re-create it inside an outer loop:\n",
    "# with GradCAM(model=model, target_layers=target_layers, use_cuda=args.use_cuda) as cam:\n",
    "#   ...\n",
    "\n",
    "# If target_category is None, the highest scoring category\n",
    "# will be used for every image in the batch.\n",
    "# target_category can also be an integer, or a list of different integers\n",
    "# for every image in the batch.\n",
    "target_category = 281\n",
    "\n",
    "# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "grayscale_cam = cam(input_tensor=input_tensor, target_category=target_category)\n",
    "\n",
    "# In this example grayscale_cam has only one image in the batch:\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "visualization = show_cam_on_image(image.numpy(), grayscale_cam, use_rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77171e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(visualization, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "024e3e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
      "\u001b[K     |████████████████████████████████| 376 kB 13.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4 in /fs/classhomes/fall2021/cmsc828w/cs828w04/anaconda3/lib/python3.8/site-packages (from timm) (1.9.1+cu111)\n",
      "Requirement already satisfied: torchvision in /fs/classhomes/fall2021/cmsc828w/cs828w04/anaconda3/lib/python3.8/site-packages (from timm) (0.10.1+cu111)\n",
      "Requirement already satisfied: typing-extensions in /fs/classhomes/fall2021/cmsc828w/cs828w04/anaconda3/lib/python3.8/site-packages (from torch>=1.4->timm) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in /fs/classhomes/fall2021/cmsc828w/cs828w04/anaconda3/lib/python3.8/site-packages (from torchvision->timm) (1.21.2)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /fs/classhomes/fall2021/cmsc828w/cs828w04/anaconda3/lib/python3.8/site-packages (from torchvision->timm) (8.3.2)\n",
      "Installing collected packages: timm\n",
      "Successfully installed timm-0.4.12\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111a1603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /fs/classhomes/fall2021/cmsc828w/cs828w04/.cache/torch/hub/facebookresearch_deit_main\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth\" to /fs/classhomes/fall2021/cmsc828w/cs828w04/.cache/torch/hub/checkpoints/deit_tiny_patch16_224-a1311bcf.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84aed3ad4bc84aaba06a9bae1d2e28fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/21.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = torch.hub.load('facebookresearch/deit:main',\n",
    "                           'deit_tiny_patch16_224', pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c7b251b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Block(\n",
       "    (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (act): GELU()\n",
       "      (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (1): Block(\n",
       "    (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (act): GELU()\n",
       "      (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (2): Block(\n",
       "    (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (act): GELU()\n",
       "      (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (3): Block(\n",
       "    (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (act): GELU()\n",
       "      (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (4): Block(\n",
       "    (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (act): GELU()\n",
       "      (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (5): Block(\n",
       "    (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (act): GELU()\n",
       "      (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (6): Block(\n",
       "    (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (act): GELU()\n",
       "      (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (7): Block(\n",
       "    (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (act): GELU()\n",
       "      (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (8): Block(\n",
       "    (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (act): GELU()\n",
       "      (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (9): Block(\n",
       "    (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (act): GELU()\n",
       "      (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (10): Block(\n",
       "    (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (act): GELU()\n",
       "      (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (11): Block(\n",
       "    (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "      (act): GELU()\n",
       "      (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
